name: Daily NBA Data Scrape Scheduler

on:
  schedule:
    - cron: '0 8 * * *' 
  workflow_dispatch:

jobs:
  scrape-data:
    runs-on: ubuntu-latest
    
    # Define where packages should be stored for caching
    env:
      R_LIBS_USER: ${{ github.workspace }}/R/library

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: 'release'
          use-public-rspm: true # Uses pre-compiled binaries for speed

      - name: Cache R packages
        uses: actions/cache@v4
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-${{ hashFiles('hnrdb_full.R') }}
          restore-keys: |
            ${{ runner.os }}-r-

      - name: Create R library directory
        run: mkdir -p ${{ env.R_LIBS_USER }}

      # Use 'pak' to safely install packages AND system dependencies
      - name: Install R packages
        run: |
          Rscript -e 'install.packages("pak", repos="https://r-lib.github.io/p/pak/devel/")'
          Rscript -e 'pak::pkg_install(c("tidyverse", "hoopR", "httr", "jsonlite", "rvest", "glue", "janitor", "fuzzyjoin", "plyr"))'

      - name: Run scraper script
        run: Rscript hnrdb_full.R

      - name: Commit and push new data
        run: |
          git config --local user.name "GitHub Actions Bot"
          git config --local user.email "actions@github.com"
          git add *.csv
          git commit -m "Auto-update daily NBA stats" || echo "No changes to commit"
          git push origin main
